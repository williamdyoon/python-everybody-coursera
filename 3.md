#Python For Everybody
##3 - Using Python to Access Web Data

###0) python version used

```python
import sys
print(sys.version)
```

```
## 2.7.10 (default, Oct 23 2015, 18:05:06) 
## [GCC 4.2.1 Compatible Apple LLVM 7.0.0 (clang-700.0.59.5)]
```

###1) regex simple examples

```python
import re
hand = open('mbox-short.txt')
for line in hand:
    line = line.rstrip()
    if re.search('^From: ', line):
        print line
        break
x = 'My 2 favorite numbers are 19 and 42'
y = re.findall('[0-9]+',x)
print y

a = 'From: Using the : character'
b = re.findall('^F.+:', a) # greedy
c = re.findall('^F.+?:', a) # NON-greedy
print "greedy:", b
print "non-greedy:", c
```

```
## From: stephen.marquard@uct.ac.za
## ['2', '19', '42']
## greedy: ['From: Using the :']
## non-greedy: ['From:']
```

###2) regex simple examples2

```python
import re
x = "From stephen.marquard@uct.ac.za Sat Jan 5 09:14:16 2008"
y = re.findall('\S+@\S+', x) # (>=1) non-whitespace character before @ and then (>=1) non-whitespace character until whitespace 
z = re.findall('^From (\S+@\S+)', x) # same as above but specific extraction for line that starts with From
print y
print z

# extracting only the domain name of the e-mail (aka "uct.ac.za")
a = re.findall('@([^ ]*)',x) # where it has @, extracts after it anything that isn't whitespace >= 0 times until whitespace
b = re.findall('@(\S*)',x)  # same as above basically
print a
print b

# extracting just numbers and collecting into a list (floating num)
hand = open('mbox-short.txt')
numlist = list()
for line in hand:
    line = line.rstrip()
    # ['X-DSPAM-Confidence: 0.8475'] needs to extract #.###
    stuff = re.findall('^X-DSPAM-Confidence: ([0-9.]+)',line) 
    if len(stuff) != 1 : continue
    num = float(stuff[0])
    numlist.append(num)
print "max:", max(numlist)

# extracting special reserved keywords
xxx = 'We just received $10.00 for cookies.'
print re.findall('\$[0-9.]+',xxx)
```

```
## ['stephen.marquard@uct.ac.za']
## ['stephen.marquard@uct.ac.za']
## ['uct.ac.za']
## ['uct.ac.za']
## max: 0.9907
## ['$10.00']
```

###3) basic connection via socket examples

```python
## does not function as instructed due to cloudflare
import socket
mysock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
mysock.connect(('www.py4inf.com',80)) #socket extablished at this point

mysock.send('GET http://www.py4inf.com/code/romeo.txt HTTP/1.0\n\n')
while True:
    data = mysock.recv(512)
    if(len(data)<1):
        break
    print data;
mysock.close()
```

```
## HTTP/1.1 400 Bad Request
## Date: Thu, 28 Jan 2016 21:26:58 GMT
## Content-Type: text/html
## Connection: close
## Set-Cookie: __cfduid=ded8c656483a054acda64fb2a67f80ea21454016418; expires=Fri, 27-Jan-17 21:26:58 GMT; path=/; domain=.py4inf.com; HttpOnly
## Server: cloudflare-nginx
## CF-RAY: 26bfc756e6f839e2-PHX
## 
## <html>
## <head><title>400 Bad Request</title></head>
## <body bgcolor="white">
## <center><h1>400 Bad Request</h1></center>
## <hr><center>cloudflare-nginx</center>
## </body>
## </html>
```

###4) revisting (3) using urllib

```python
## same error due to cloudflare protection system, hence used github raw file format
import urllib
fhand = urllib.urlopen('https://raw.githubusercontent.com/williamdyoon/python-everybody-coursera/master/romeo.txt')
for line in fhand:
    print line.strip()

## urllib allows similar functionality as file handler
counts = dict()
fhand = urllib.urlopen('https://raw.githubusercontent.com/williamdyoon/python-everybody-coursera/master/romeo.txt')
for line in fhand:
    words = line.split()
    for word in words:
        counts[word] = counts.get(word,0) + 1
print counts
```

```
## But soft what light through yonder window breaks
## It is the east and Juliet is the sun
## Arise fair sun and kill the envious moon
## Who is already sick and pale with grief
## {'and': 3, 'envious': 1, 'already': 1, 'fair': 1, 'is': 3, 'through': 1, 'pale': 1, 'yonder': 1, 'what': 1, 'sun': 2, 'Who': 1, 'But': 1, 'moon': 1, 'window': 1, 'sick': 1, 'east': 1, 'breaks': 1, 'grief': 1, 'with': 1, 'light': 1, 'It': 1, 'Arise': 1, 'kill': 1, 'the': 3, 'soft': 1, 'Juliet': 1}
```

###5) understanding HTML samples

```python
import urllib
fhand = urllib.urlopen('http://www.dr-chuck.com/page1.html')
for line in fhand:
    print line.strip()
```

```
## <h1>The First Page</h1>
## <p>
## If you like, you can switch to the
## <a href="http://www.dr-chuck.com/page2.htm">
## Second Page</a>.
## </p>
```

###6) parsing HTML with BeautifulSoup (REQUIRES BeautifulSoup)

```python
import urllib
from BeautifulSoup import *
html = urllib.urlopen('http://www.dr-chuck.com/page1.html').read()
soup = BeautifulSoup(html)
tags = soup('a')
for tag in tags:
    print tag.get('href', None)
```

```
## http://www.dr-chuck.com/page2.htm
```
