---
output: 
  html_document: 
    keep_md: yes
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(cache=TRUE, engine='python')
```
#Python For Everybody
##4 - Using Databases with Python

###0) python version used
```{r}
import sys
print(sys.version)
```

###1) object oriented python intro
```{r}
movies = list()
movie1={"Director" : "James Cameron", "Title" : "Avatar", "Release Date" : "18 December 2009", "Running Time" : "162 minutes", "Rating" : "PG-13"}
movies.append(movie1)
movie2={"Director" : "David Fincher", "Title" : "The Social Network", "Release Date" : "01 October 2010", "Running Time" : "120 minutes", "Rating" : "PG-13"}
movies.append(movie2)

keys = ["Title", "Director", "Rating", "Running Time"]
print movies
for item in movies:
    print "-------------------------"
    for key in keys:
        print key + ":", item[key] # because we expect the list of dictionary to contain values for the keys
print "-------------------------"
```

###2) simple python objects example
```{r}
class PartyAnimal:
    x = 0
    def party(self):
        self.x = self.x + 1
        print "So far", self.x
an = PartyAnimal() # instance with initial x attribute equaling 0
print "type:", type(an)
print "dir:", dir(an)
an.party() # increments x attribute by 1, prints it (1)
an.party() # "" (2)
an.party() # "" (3)
```

###3) simple demonstration of object lifecycle1
```{r}
class PartyAnimal:
    x = 0
    def __init__(self): ## two underscores each side
        print "I am constructed"
    def party(self):
        self.x = self.x + 1
        print "So far", self.x
    def __del__(self): ## destructor
        print "I am destructed", self.x
an = PartyAnimal()
an.party()
an.party()
an.party()
```

###4) simple demonstration of object lifecycle2
```{r}
class PartyAnimal:
    x = 0
    name = ""
    def __init__(self,nam):
        self.name = nam
        print self.name, "constructed"
    def party(self):
        self.x = self.x + 1
        print self.name, "party count", self.x
s = PartyAnimal("Sally")
s.party()
j = PartyAnimal("Jim")
j.party()
s.party()
```

###5) inheritance simple example
```{r}
class PartyAnimal:
    x = 0
    name = ""
    def __init__(self,nam):
        self.name = nam
        print self.name, "constructed"
    def party(self):
        self.x = self.x + 1
        print self.name, "party count", self.x
class FootballFan(PartyAnimal): # inherits all of the PartyAnimal class
    points = 0
    def touchdown(self):
        self.points = self.points + 7
        self.party() # inherited method from Parent class
        print self.name, "points", self.points
s = PartyAnimal("Sally")
s.party()
j = FootballFan("Jim") # inherits or extends Parent's attributes x,name
j.party()
j.touchdown()
```

###6) email database demo example
```{r}
import sqlite3
conn = sqlite3.connect('emaildb.sqlite')
cur = conn.cursor()
cur.execute('''
DROP TABLE IF EXISTS Counts''')
cur.execute('''
CREATE TABLE Counts (email TEXT, count INTEGER)''')
fname = "mbox-short.txt"
if(len(fname)<1) : fname = "mbox-short.txt"
fh = open(fname)
for line in fh:
    if not line.startswith("From: ") : continue
    pieces = line.split()
    print "->",pieces,"<-"
    email = pieces[1]
    '''******************************************************
    ? is a placeholder -- that it is going to be something
    (email,) is a tuple (row) -- email gets substituted for ? 
    parameter substitution using ? is a safety measure
    *******************************************************'''
    cur.execute('SELECT count FROM Counts WHERE email = ?', (email, ))
    # if email matches the one in the database, increments count by 1
    try:
        count = cur.fetchone()[0]
        cur.execute('UPDATE Counts SET count=count+1 WHERE email = ?',
                    (email,))
    # if db has not seen the email yet, set the value of count as 1
    except:
        cur.execute('''INSERT INTO Counts (email, count)
                    VALUES (?,1)''',(email,))
    conn.commit()
    
# obtaining top 10 descending counts of emails
sqlstr = "SELECT email, count FROM Counts ORDER BY count DESC LIMIT 10"

for row in cur.execute(sqlstr) : # row is a tuple
    print str(row[0]), row[1] # str in case UTF-8
```

###7) counting organization SQL assignment
```{r}
## count by organization (domain name of email)
import re
import sqlite3
conn = sqlite3.connect('emaildb_assignment.sqlite')
cur = conn.cursor()
cur.execute('''
DROP TABLE IF EXISTS Counts''')
cur.execute('''
CREATE TABLE Counts (org TEXT, count INTEGER)''')
fname = "mbox.txt"
fh = open(fname)

for line in fh:
    if not line.startswith("From "): continue
    line = line.rstrip()
    #org = re.findall("@(\S+)\s*",line)[0]
    orglist = re.findall("@(\S+)\s*",line)
    if len(orglist) > 0 :
        org = orglist[0]
        cur.execute('SELECT count FROM Counts WHERE org = ?', (org, ))
    # if email matches the one in the dKatabase, increments count by 1
    try:
        count = cur.fetchone()[0]
        cur.execute('UPDATE Counts SET count=count+1 WHERE org = ?',
                    (org,))
    # if db has not seen the email yet, set the value of count as 1
    except:
        cur.execute('''INSERT INTO Counts (org, count)
                    VALUES (?,1)''',(org,))
conn.commit()

sqlstr = "SELECT org, count FROM Counts ORDER BY count DESC"

for row in cur.execute(sqlstr) : # row is a tuple
    print "->"+str(row[0])+"<-", row[1] # str in case UTF-8
```

###8) connecting XML and SQL using python demo
```{r}
import xml.etree.ElementTree as ET
import sqlite3

conn = sqlite3.connect('trackdb.sqlite')
cur = conn.cursor()

cur.execute("DROP TABLE IF EXISTS Artist")
cur.execute("DROP TABLE IF EXISTS Album")
cur.execute("DROP TABLE IF EXISTS Track")


cur.execute('''
CREATE TABLE IF NOT EXISTS Artist (
    id   INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT UNIQUE,
    name TEXT UNIQUE
)''')
cur.execute('''
CREATE TABLE IF NOT EXISTS Album (
    id        INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT UNIQUE,
    artist_id INTEGER,
    title     TEXT UNIQUE
)''')
cur.execute('''
CREATE TABLE IF NOT EXISTS Track (
    id        INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT UNIQUE,
    album_id  INTEGER,
    title     TEXT UNIQUE,
    len       INTEGER,
    rating    INTEGER,
    count     INTEGER
)''')
fname = "Library.xml"

''' example of XML format
<key>Track ID</key><integer>369</integer>
<key>Name</key><string>Another One Bites The Dust</string>
<key>Artist</key><string>Queen</string>'''

## function that returns the child text if the dictionary contains the key
def lookup(d, key):
    found = False
    for child in d:
        if found: return child.text
        if child.tag == "key" and child.text == key :
            found = True
    return None
stuff = ET.parse(fname)
## three <dict> level deep inside (just the way how Library.xml handles)
all = stuff.findall("dict/dict/dict")
print "Dict count:", len(all)
for entry in all:
    if(lookup(entry,"Track ID") is None): continue
    name = lookup(entry, "Name")
    artist = lookup(entry, "Artist")
    album = lookup(entry, "Album")
    count = lookup(entry, "Play Count")
    rating = lookup(entry, "Rating")
    length = lookup(entry, "Total Time")
    
    # error check
    if name is None or artist is None or album is None:
        continue
    
    # INSERT if it's not there, and IGNORE if it's already there, or if error
    cur.execute("INSERT OR IGNORE INTO Artist (name) VALUES (?)",(artist,))
    # get the artist_id for the artist that was added 
    cur.execute("SELECT id FROM Artist WHERE name = ?",(artist,))
    artist_id = cur.fetchone()[0]
    
    cur.execute('''INSERT OR IGNORE INTO Album (title, artist_id) 
                VALUES(?,?)''',(album,artist_id))
    cur.execute("SELECT id FROM Album where title = ?", (album,))
    album_id = cur.fetchone()[0]
    
    cur.execute('''INSERT OR REPLACE INTO TRACK (title, album_id, len, rating, count)
                VALUES (?,?,?,?,?)''',(name,album_id,length,rating,count))
conn.commit()
```

###9) music track database assignment
```{r}
import xml.etree.ElementTree as ET
import sqlite3
conn = sqlite3.connect('trackdb_assignment.sqlite')
cur = conn.cursor()
cur.execute("DROP TABLE IF EXISTS Artist")
cur.execute("DROP TABLE IF EXISTS Genre")
cur.execute("DROP TABLE IF EXISTS Album")
cur.execute("DROP TABLE IF EXISTS Track")
cur.execute('''
CREATE TABLE Artist (
    id  INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT UNIQUE,
    name    TEXT UNIQUE
);''')
cur.execute('''
CREATE TABLE Genre (
    id  INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT UNIQUE,
    name    TEXT UNIQUE
);''')
cur.execute('''
CREATE TABLE Album (
    id  INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT UNIQUE,
    artist_id  INTEGER,
    title   TEXT UNIQUE
);''')
cur.execute('''
CREATE TABLE Track (
    id  INTEGER NOT NULL PRIMARY KEY 
        AUTOINCREMENT UNIQUE,
    title TEXT  UNIQUE,
    album_id  INTEGER,
    genre_id  INTEGER,
    len INTEGER, rating INTEGER, count INTEGER
);''')
fname = "Library.xml"
def lookup(d, key):
    found = False
    for child in d:
        if found: return child.text
        if child.tag == "key" and child.text == key :
            found = True
    return None
stuff = ET.parse(fname)
all = stuff.findall("dict/dict/dict")
for entry in all:
    if(lookup(entry,"Track ID") is None): continue
    genre_name = lookup(entry, "Genre")
    artist_name = lookup(entry, "Artist")
    album_title = lookup(entry, "Album")
    track_title = lookup(entry, "Name")
    track_len = lookup(entry, "Total Time")
    track_rating = lookup(entry, "Rating")
    track_count = lookup(entry, "Play Count")
    if (genre_name is None or artist_name is None or 
        album_title is None or track_title is None): continue
    cur.execute("INSERT OR IGNORE INTO Genre (name) VALUES (?)", (genre_name,))
    cur.execute("SELECT id FROM Genre WHERE name = ?", (genre_name,))
    genre_id = cur.fetchone()[0]
    
    cur.execute("INSERT OR IGNORE INTO Artist (name) VALUES (?)", (artist_name,))
    cur.execute("SELECT id FROM Artist WHERE name = ?", (artist_name,))
    artist_id = cur.fetchone()[0]
    
    cur.execute("INSERT OR IGNORE INTO Album (artist_id, title) VALUES (?,?)", 
                (artist_id, album_title))
    cur.execute("SELECT id from Album where title = ?", (album_title,))
    album_id = cur.fetchone()[0]
    cur.execute('''INSERT OR REPLACE INTO Track 
                (title, album_id, genre_id, len, rating, count)
                VALUES (?,?,?,?,?,?)''',
                (track_title, album_id, genre_id, track_len, track_rating, track_count)
    )
conn.commit()
sql_query = '''
SELECT Track.title, Artist.name, Album.title, Genre.name 
    FROM Track JOIN Genre JOIN Album JOIN Artist 
    ON Track.genre_id = Genre.ID and Track.album_id = Album.id 
        AND Album.artist_id = Artist.id
    ORDER BY Artist.name, Track.title LIMIT 3
'''
for iteration in cur.execute(sql_query):
    print str(iteration[0]), ";", str(iteration[1]), ";", str(iteration[2]), ";", str(iteration[3])
```

###10) many-to-many relationships in SQL example
```{r}
import xml.etree.ElementTree as ET
import sqlite3
conn = sqlite3.connect('manytomany_ex.sqlite')
cur = conn.cursor()
cur.execute("DROP TABLE IF EXISTS User")
cur.execute("DROP TABLE IF EXISTS Course")
cur.execute("DROP TABLE IF EXISTS Member")
cur.execute('''
CREATE TABLE User (
    id  INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT UNIQUE,
    name    TEXT,
    email   TEXT
);''')
cur.execute('''
CREATE TABLE Course (
    id  INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT UNIQUE,
    title    TEXT UNIQUE
);''')
cur.execute('''
CREATE TABLE Member (
    user_id    INTEGER,
    course_id  INTEGER,
    role    INTEGER,
    PRIMARY KEY (user_id, course_id)
);''')
# PRIMARY KEY makes it unique -- combination of unique

cur.execute('''INSERT INTO User (name, email) values ("Jane","jane@tsugi.org");''')
cur.execute('''INSERT INTO User (name, email) values ("Ed","ed@tsugi.org");''')
cur.execute('''INSERT INTO User (name, email) values ("Sue","su@tsugi.org");''')
cur.execute('''INSERT INTO Course (title) values ("Python");''')
cur.execute('''INSERT INTO Course (title) values ("SQL");''')
cur.execute('''INSERT INTO Course (title) values ("PHP");''')
### role: 1 instructor, 0 student, 
cur.execute('''INSERT INTO Member (user_id, course_id, role) values (1,1,1);''')
cur.execute('''INSERT INTO Member (user_id, course_id, role) values (2,1,0);''')
cur.execute('''INSERT INTO Member (user_id, course_id, role) values (3,1,0);''')
cur.execute('''INSERT INTO Member (user_id, course_id, role) values (1,2,0);''')
cur.execute('''INSERT INTO Member (user_id, course_id, role) values (2,2,1);''')
cur.execute('''INSERT INTO Member (user_id, course_id, role) values (2,3,1);''')
cur.execute('''INSERT INTO Member (user_id, course_id, role) values (3,3,0);''')
conn.commit()
sql_query = '''
SELECT User.name, Member.role, Course.title
FROM User JOIN Member JOIN Course
ON Member.user_id = User.id AND Member.course_id = Course.id
ORDER BY Course.title, Member.role DESC, User.name
'''
for i in cur.execute(sql_query):
    print i[0], i[1], i[2]
```

###11) many-to-many roster demo
```{r}
import json
import sqlite3
conn = sqlite3.connect('rosterdb.sqlite')
cur = conn.cursor()
cur.executescript('''
DROP TABLE IF EXISTS User;
DROP TABLE IF EXISTS Member;
DROP TABLE IF EXISTS Course;

CREATE TABLE User (
    id  INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT UNIQUE,
    name    TEXT UNIQUE
);
CREATE TABLE Course (
    id  INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT UNIQUE,
    title    TEXT UNIQUE
);
CREATE TABLE Member (
    user_id    INTEGER,
    course_id  INTEGER,
    PRIMARY KEY (user_id, course_id)
);
''')

fname = "roster_data.json"

### json of list of list of data
### file format in json
# [
#    [ "Charley", "sill0", 1],
#    [ "Mea", "sill0", 0], 
#    ...
str_data = open(fname).read()
json_data = json.loads(str_data)

for entry in json_data:
    name = entry[0]
    title = entry[1]
    cur.execute('''INSERT OR IGNORE INTO User(name) VALUES(?)''',(name,))
    cur.execute('''SELECT id FROM User WHERE name=?''',(name,))
    user_id=cur.fetchone()[0]
    
    cur.execute('''INSERT OR IGNORE INTO Course(title) VALUES(?)''',(title,))
    cur.execute('''SELECT id FROM Course WHERE title=?''',(title,))
    course_id=cur.fetchone()[0]
    
    cur.execute('''INSERT OR REPLACE INTO Member(user_id,course_id) VALUES(?,?)''',
                (user_id,course_id))
conn.commit()
```

###12) many-to-many roster assignment
```{r}
import json, sqlite3
conn = sqlite3.connect('rosterdb_assignment.sqlite')
cur = conn.cursor()
cur.executescript('''
DROP TABLE IF EXISTS User;
DROP TABLE IF EXISTS Member;
DROP TABLE IF EXISTS Course;
CREATE TABLE User (
    id  INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT UNIQUE,
    name    TEXT UNIQUE
);
CREATE TABLE Course (
    id  INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT UNIQUE,
    title    TEXT UNIQUE
);
CREATE TABLE Member (
    user_id    INTEGER,
    course_id  INTEGER,
    role INTEGER,
    PRIMARY KEY (user_id, course_id)
);''')
fname = "roster_data_assignment.json"
json_data = json.loads(open(fname).read())
for entry in json_data:
    name = entry[0]
    title = entry[1]
    role = entry[2]
    cur.execute('''INSERT OR IGNORE INTO User(name) VALUES(?)''',(name,))
    cur.execute('''SELECT id FROM User WHERE name=?''',(name,))
    user_id=cur.fetchone()[0]
    cur.execute('''INSERT OR IGNORE INTO Course(title) VALUES(?)''',(title,))
    cur.execute('''SELECT id FROM Course WHERE title=?''',(title,))
    course_id=cur.fetchone()[0]
    cur.execute('''INSERT OR REPLACE INTO Member(user_id,course_id,role) VALUES(?,?,?)''',
                (user_id,course_id,role))
conn.commit()
sql_query = '''
SELECT hex(User.name || Course.title || Member.role ) AS X FROM 
    User JOIN Member JOIN Course 
    ON User.id = Member.user_id AND Member.course_id = Course.id
    ORDER BY X LIMIT 1
'''
for i in cur.execute(sql_query):
    print i[0]
```

###13) databases and visualization-geocoding demo1
```{r}
print "geoload.py"
# ********************************** geoload.py ****************************************
# ******************************* gathering step ***************************************
import urllib, sqlite3, json, ssl
serviceurl = "http://maps.googleapis.com/maps/api/geocode/json?"
scontext = None
conn = sqlite3.connect('geodata-demo.sqlite')
cur = conn.cursor()
cur.execute('''CREATE TABLE IF NOT EXISTS Locations (address TEXT, geodata TEXT)''')
fh = open("where-mini.data")
count = 0
for line in fh:
    if count > 200 : break
    address = line.strip()
    cur.execute("SELECT geodata FROM Locations WHERE address= ?", (buffer(address), ))
    try:
        data = cur.fetchone()[0]
        print "Found in database",address
        continue
    except:
        pass
    url = serviceurl + urllib.urlencode({"sensor":"false", "address": address})
    print 'Retrieving', url
    uh = urllib.urlopen(url, context=scontext)
    data = uh.read()
    print 'Retrieved',len(data),'characters',data[:20].replace('\n',' ')
    count = count + 1
    try: 
        js = json.loads(str(data))
    except: 
        continue
    if 'status' not in js or (js['status'] != 'OK' and js['status'] != 'ZERO_RESULTS') : 
        print '==== Failure To Retrieve ===='
        print data
        break
    cur.execute('''INSERT INTO Locations(address,geodata)VALUES (?,?)''',(buffer(address),buffer(data)))
    conn.commit()
print "\ngeodump.py"
# ********************************** geodump.py ****************************************
# ********************************* dumping step ***************************************
import sqlite3, json, codecs
conn = sqlite3.connect('geodata-demo.sqlite')
cur = conn.cursor()
cur.execute('SELECT * FROM Locations')
fhand = codecs.open('where.js','w', "utf-8")
fhand.write("myData = [\n")
count = 0
for row in cur :
    data = str(row[1])
    try: js = json.loads(str(data))
    except: continue
    if not('status' in js and js['status'] == 'OK') : continue
    lat = js["results"][0]["geometry"]["location"]["lat"]
    lng = js["results"][0]["geometry"]["location"]["lng"]
    if lat == 0 or lng == 0 : continue
    where = js['results'][0]['formatted_address']
    where = where.replace("'","")
    try :
        print where, lat, lng
        count = count + 1
        if count > 1 : fhand.write(",\n")
        output = "["+str(lat)+","+str(lng)+", '"+where+"']"
        fhand.write(output)
    except:
        continue
fhand.write("\n];\n")
cur.close()
fhand.close()
print count, "records written to where.js"
```

###14) databases and visualization-geocoding demo2
```{r echo=FALSE}
print "visualizing where.js"
# *********************************** where.js *****************************************
# ****************************** visualization step ************************************
```
<script src="http://maps.googleapis.com/maps/api/js?sensor=false"></script>
<script src="where.js"></script>
<script>
      function initialize() {
        var myLatlng = new google.maps.LatLng(37.39361,-122.099263)
        var mapOptions = {
          zoom: 2,
          center: myLatlng,
          mapTypeId: google.maps.MapTypeId.ROADMAP
        }
        var map = new google.maps.Map(document.getElementById('map_canvas'), mapOptions);

        i = 0;
        var markers = [];
        for ( pos in myData ) {
            i = i + 1;
            var row = myData[pos];
		    window.console && console.log(row);
            // if ( i < 3 ) { alert(row); }
            var newLatlng = new google.maps.LatLng(row[0], row[1]);
            var marker = new google.maps.Marker({
                position: newLatlng,
                map: map,
                title: row[2]
            });
            markers.push(marker);}}</script>
<body onload="initialize()">
<div id="map_canvas" style="height: 500px"></div>
</body>

###15) page ranks and web searching demo1
```{r}
print "spider.py"
# *************************************** spider.py ************************************
# ****************************** obtaining data from the web ***************************
import sqlite3
import urllib
import ssl 
from urlparse import urljoin
from urlparse import urlparse
from BeautifulSoup import *
scontext = None
conn = sqlite3.connect('spider-demo.sqlite')
cur = conn.cursor()
cur.execute('''CREATE TABLE IF NOT EXISTS Pages 
    (id INTEGER PRIMARY KEY, url TEXT UNIQUE, html TEXT, 
     error INTEGER, old_rank REAL, new_rank REAL)''')
cur.execute('''CREATE TABLE IF NOT EXISTS Links 
    (from_id INTEGER, to_id INTEGER)''')
cur.execute('''CREATE TABLE IF NOT EXISTS Webs (url TEXT UNIQUE)''')
cur.execute('SELECT id,url FROM Pages WHERE html is NULL and error is NULL ORDER BY RANDOM() LIMIT 1')
row = cur.fetchone()
if row is not None:
    print "Restarting existing crawl.  Remove spider-demo.sqlite to start a fresh crawl."
else :
    starturl = "http://www.dr-chuck.com/"
    if ( starturl.endswith('/') ) : starturl = starturl[:-1]
    web = starturl
    if ( starturl.endswith('.htm') or starturl.endswith('.html') ) :
        pos = starturl.rfind('/')
        web = starturl[:pos]
    if ( len(web) > 1 ) :
        cur.execute('INSERT OR IGNORE INTO Webs (url) VALUES ( ? )', ( web, ) )
        cur.execute('INSERT OR IGNORE INTO Pages (url, html, new_rank) VALUES ( ?, NULL, 1.0 )', ( starturl, ) ) 
        conn.commit()
cur.execute('''SELECT url FROM Webs''')
webs = list()
for row in cur:
    webs.append(str(row[0]))
print webs
many = 0
while True:
    many = many + 1
    cur.execute('SELECT id,url FROM Pages WHERE html is NULL and error is NULL ORDER BY RANDOM() LIMIT 1')
    try:
        row = cur.fetchone()
        # print row
        fromid = row[0]
        url = row[1]
    except:
        print 'No unretrieved HTML pages found'
        many = 0
        break
    print fromid, url, 
    cur.execute('DELETE from Links WHERE from_id=?', (fromid, ) )
    try:
        document = urllib.urlopen(url, context=scontext)
        html = document.read()
        if document.getcode() != 200 :
            print "Error on page: ",document.getcode()
            cur.execute('UPDATE Pages SET error=? WHERE url=?', (document.getcode(), url) )
        if 'text/html' != document.info().gettype() :
            print "Ignore non text/html page"
            cur.execute('DELETE FROM Pages WHERE url=?', ( url, ) ) 
            cur.execute('UPDATE Pages SET error=0 WHERE url=?', (url, ) )
            conn.commit()
            continue
        print '('+str(len(html))+')',
        soup = BeautifulSoup(html)
    except KeyboardInterrupt:
        print ''
        print 'Program interrupted by user...'
        break
    except:
        print "Unable to retrieve or parse page"
        cur.execute('UPDATE Pages SET error=-1 WHERE url=?', (url, ) )
        conn.commit()
        continue
    cur.execute('INSERT OR IGNORE INTO Pages (url, html, new_rank) VALUES ( ?, NULL, 1.0 )', ( url, ) )
    cur.execute('UPDATE Pages SET html=? WHERE url=?', (buffer(html), url ) )
    conn.commit()
    tags = soup('a')
    count = 0
    for tag in tags:
        href = tag.get('href', None)
        if ( href is None ) : continue
        up = urlparse(href)
        if ( len(up.scheme) < 1 ) :
            href = urljoin(url, href)
        ipos = href.find('#')
        if ( ipos > 1 ) : href = href[:ipos]
        if ( href.endswith('.png') or href.endswith('.jpg') or href.endswith('.gif') ) : continue
        if ( href.endswith('/') ) : href = href[:-1]
        if ( len(href) < 1 ) : continue
        found = False
        for web in webs:
            if ( href.startswith(web) ) :
                found = True
                break
        if not found : continue
        cur.execute('INSERT OR IGNORE INTO Pages (url, html, new_rank) VALUES ( ?, NULL, 1.0 )', ( href, ) ) 
        count = count + 1
        conn.commit()
        cur.execute('SELECT id FROM Pages WHERE url=? LIMIT 1', ( href, ))
        try:
            row = cur.fetchone()
            toid = row[0]
        except:
            print 'Could not retrieve id'
            continue
        cur.execute('INSERT OR IGNORE INTO Links (from_id, to_id) VALUES ( ?, ? )', ( fromid, toid ) ) 
    print count
    if many == 10:
        break
cur.close()
    
print "\nsprank.py with 100 iterations"
# *************************************** sprank.py ************************************
# ************************************* ranking step ***********************************
import sqlite3
conn = sqlite3.connect('spider-demo.sqlite')
cur = conn.cursor()
cur.execute('''SELECT DISTINCT from_id FROM Links''')
from_ids = list()
for row in cur: 
    from_ids.append(row[0])
to_ids = list()
links = list()
cur.execute('''SELECT DISTINCT from_id, to_id FROM Links''')
for row in cur:
    from_id = row[0]
    to_id = row[1]
    if from_id == to_id : continue
    if from_id not in from_ids : continue
    if to_id not in from_ids : continue
    links.append(row)
    if to_id not in to_ids : to_ids.append(to_id)
prev_ranks = dict()
for node in from_ids:
    cur.execute('''SELECT new_rank FROM Pages WHERE id = ?''', (node, ))
    row = cur.fetchone()
    prev_ranks[node] = row[0]
sval = 100
many = 1
many = int(sval)
if len(prev_ranks) < 1 : 
    print "Nothing to page rank.  Check data."
    quit()
for i in range(many):
    next_ranks = dict();
    total = 0.0
    for (node, old_rank) in prev_ranks.items():
        total = total + old_rank
        next_ranks[node] = 0.0
    for (node, old_rank) in prev_ranks.items():
        give_ids = list()
        for (from_id, to_id) in links:
            if from_id != node : continue
            if to_id not in to_ids: continue
            give_ids.append(to_id)
        if ( len(give_ids) < 1 ) : continue
        amount = old_rank / len(give_ids)    
        for id in give_ids:
            next_ranks[id] = next_ranks[id] + amount
    newtot = 0
    for (node, next_rank) in next_ranks.items():
        newtot = newtot + next_rank
    evap = (total - newtot) / len(next_ranks)
    for node in next_ranks:
        next_ranks[node] = next_ranks[node] + evap
    newtot = 0
    for (node, next_rank) in next_ranks.items():
        newtot = newtot + next_rank
    totdiff = 0
    for (node, old_rank) in prev_ranks.items():
        new_rank = next_ranks[node]
        diff = abs(old_rank-new_rank)
        totdiff = totdiff + diff
    avediff = totdiff / len(prev_ranks)
    prev_ranks = next_ranks
cur.execute('''UPDATE Pages SET old_rank=new_rank''')
for (id, new_rank) in next_ranks.items() :
    cur.execute('''UPDATE Pages SET new_rank=? WHERE id=?''', (new_rank, id))
conn.commit()
cur.close()
print "\nspdump.py"
# *********************************** spdump.py ****************************************
# ********************************* dumping step ***************************************
import sqlite3
conn = sqlite3.connect('spider-demo.sqlite')
cur = conn.cursor()
cur.execute('''SELECT COUNT(from_id) AS inbound, old_rank, new_rank, id, url 
     FROM Pages JOIN Links ON Pages.id = Links.to_id
     WHERE html IS NOT NULL
     GROUP BY id ORDER BY inbound DESC''')
count = 0
for row in cur :
    if count < 50 : print row
    count = count + 1
print count, 'rows.'
cur.close()
print "\nspjson.py"
# *********************************** spjson.py ****************************************
# ***************************** json generation step ***********************************
import sqlite3
conn = sqlite3.connect('spider-demo.sqlite')
cur = conn.cursor()
print "Creating JSON output on spider-demo.js..."
#howmany = int(raw_input("How many nodes? "))
howmany = 100
cur.execute('''SELECT COUNT(from_id) AS inbound, old_rank, new_rank, id, url 
    FROM Pages JOIN Links ON Pages.id = Links.to_id
    WHERE html IS NOT NULL AND ERROR IS NULL
    GROUP BY id ORDER BY id,inbound''')
fhand = open('spider-demo.js','w')
nodes = list()
maxrank = None
minrank = None
for row in cur :
    nodes.append(row)
    rank = row[2]
    if maxrank < rank or maxrank is None : maxrank = rank
    if minrank > rank or minrank is None : minrank = rank
    if len(nodes) > howmany : break
if maxrank == minrank or maxrank is None or minrank is None:
    print "Error - please run sprank.py to compute page rank"
    quit()
fhand.write('spiderJson = {"nodes":[\n')
count = 0
map = dict()
ranks = dict()
for row in nodes :
    if count > 0 : fhand.write(',\n')
    rank = row[2]
    rank = 19 * ( (rank - minrank) / (maxrank - minrank) ) 
    fhand.write('{'+'"weight":'+str(row[0])+',"rank":'+str(rank)+',')
    fhand.write(' "id":'+str(row[3])+', "url":"'+row[4]+'"}')
    map[row[3]] = count
    ranks[row[3]] = rank
    count = count + 1
fhand.write('],\n')
cur.execute('''SELECT DISTINCT from_id, to_id FROM Links''')
fhand.write('"links":[\n')
count = 0
for row in cur :
    if row[0] not in map or row[1] not in map : continue
    if count > 0 : fhand.write(',\n')
    rank = ranks[row[0]]
    srank = 19 * ( (rank - minrank) / (maxrank - minrank) ) 
    fhand.write('{"source":'+str(map[row[0]])+',"target":'+str(map[row[1]])+',"value":3}')
    count = count + 1
fhand.write(']};')
fhand.close()
cur.close()
```

###16) page ranks and web searching demo2
```{r echo=FALSE}
print "visualizing spider-demo.js"
# ******************************** spider-demo.js **************************************
# ****************************** visualization step ************************************
```
<html><head>
<script type="text/javascript" src="d3.v2.js"></script>
<script type="text/javascript" src="spider-demo.js"></script>
<link type="text/css" rel="stylesheet" href="force.css"/>
</head>
<body style="font-family: sans-serif;">
<script>document.write("<p>Starting url: "+spiderJson.nodes[0].url+"</p>");</script>
<div id="chart" style="border:1px"></div>
<script type="text/javascript" src="force.js"></script>
</body>
</html>

###17) gmane mailing lists demo1
```{r}
print "gmane.py"
# ************************************** gmane.py **************************************
# *********************************** gathering step ***********************************
import sqlite3
#import time
import ssl
import urllib
from urlparse import urljoin
from urlparse import urlparse
import re
from datetime import datetime, timedelta
scontext = None
# Not all systems have this so conditionally define parser
try:
    import dateutil.parser as parser
except:
    pass
def parsemaildate(md) :
    # See if we have dateutil
    try:
        pdate = parser.parse(tdate)
        test_at = pdate.isoformat()
        return test_at
    except:
        pass
    # Non-dateutil version - we try our best
    pieces = md.split()
    notz = " ".join(pieces[:4]).strip()
    # Try a bunch of format variations - strptime() is *lame*
    dnotz = None
    for form in [ '%d %b %Y %H:%M:%S', '%d %b %Y %H:%M:%S',
        '%d %b %Y %H:%M', '%d %b %Y %H:%M', '%d %b %y %H:%M:%S',
        '%d %b %y %H:%M:%S', '%d %b %y %H:%M', '%d %b %y %H:%M' ] :
        try:
            dnotz = datetime.strptime(notz, form)
            break
        except:
            continue
    if dnotz is None :
        return None
    iso = dnotz.isoformat()
    tz = "+0000"
    try:
        tz = pieces[4]
        ival = int(tz) # Only want numeric timezone values
        if tz == '-0000' : tz = '+0000'
        tzh = tz[:3]
        tzm = tz[3:]
        tz = tzh+":"+tzm
    except:
        pass
    return iso+tz
conn = sqlite3.connect('content-demo.sqlite')
cur = conn.cursor()
conn.text_factory = str
baseurl = "http://gmane.dr-chuck.net/gmane.comp.cms.sakai.devel/"
cur.execute('''CREATE TABLE IF NOT EXISTS Messages 
    (id INTEGER UNIQUE, email TEXT, sent_at TEXT, 
     subject TEXT, headers TEXT, body TEXT)''')
# This will be manually filled in
cur.execute('''CREATE TABLE IF NOT EXISTS Mapping 
    (old TEXT, new TEXT)''')
# This will be manually filled in
cur.execute('''CREATE TABLE IF NOT EXISTS DNSMapping 
    (old TEXT, new TEXT)''')
start = 0
many = 0
while True:
    if ( many < 1 ) :
        #sval = raw_input('How many messages:')
        #if ( len(sval) < 1 ) : break
        sval = 100
        many = int(sval)
    start = start + 1
    cur.execute('SELECT id FROM Messages WHERE id=?', (start,) )
    try:
        row = cur.fetchone()
        if row is not None : continue
    except:
        row = None
    many = many - 1
    url = baseurl + str(start) + '/' + str(start + 1)
    try:
        document = urllib.urlopen(url, context=scontext)
        text = document.read()
        if document.getcode() != 200 :
            print "Error code=",document.getcode(), url
            break
    except KeyboardInterrupt:
        print ''
        print 'Program interrupted by user...'
        break
    except:
        print "Unable to retrieve or parse page",url
        break
    if not text.startswith("From "):
        print text
        print "End of mail stream reached..."
        quit ()
    pos = text.find("\n\n")
    if pos > 0 : 
        hdr = text[:pos]
        body = text[pos+2:]
    else:
        print text
        print "Could not find break between headers and body"
        break
    email = None
    x = re.findall('\nFrom: .* <(\S+@\S+)>\n', hdr)
    if len(x) == 1 : 
        email = x[0];
        email = email.strip().lower()
        email = email.replace("<","")
    else:
        x = re.findall('\nFrom: (\S+@\S+)\n', hdr)
        if len(x) == 1 : 
            email = x[0];
            email = email.strip().lower()
            email = email.replace("<","")
    date = None
    y = re.findall('\Date: .*, (.*)\n', hdr)
    if len(y) == 1 : 
        tdate = y[0]
        tdate = tdate[:26]
        try:
            sent_at = parsemaildate(tdate)
        except:
            print text
            print "Parse fail",tdate
            break
    subject = None
    z = re.findall('\Subject: (.*)\n', hdr)
    if len(z) == 1 : subject = z[0].strip().lower();
    cur.execute('''INSERT OR IGNORE INTO Messages (id, email, sent_at, subject, headers, body)
        VALUES ( ?, ?, ?, ?, ?, ? )''', ( start, email, sent_at, subject, hdr, body))
    conn.commit()
    if many < 1:
        break
cur.close()
print "\ngmodel.py"
# ************************************** gmodel.py *************************************
# *********************************** remodeling step **********************************
import sqlite3
import urllib
import re
import zlib
from datetime import datetime, timedelta
try:
    import dateutil.parser as parser 
except:
    pass
dnsmapping = dict()
mapping = dict()
def fixsender(sender,allsenders=None) :
    global dnsmapping
    global mapping
    if sender is None : return None
    sender = sender.strip().lower()
    sender = sender.replace('<','').replace('>','')
    # Check if we have a hacked gmane.org from address
    if allsenders is not None and sender.endswith('gmane.org') : 
        pieces = sender.split('-')
        realsender = None
        for s in allsenders:
            if s.startswith(pieces[0]) :
                realsender = sender
                sender = s
                # print realsender, sender
                break
        if realsender is None : 
            for s in mapping:
                if s.startswith(pieces[0]) :
                    realsender = sender
                    sender = mapping[s]
                    # print realsender, sender
                    break
        if realsender is None : sender = pieces[0]
    mpieces = sender.split("@")
    if len(mpieces) != 2 : return sender
    dns = mpieces[1]
    x = dns
    pieces = dns.split(".")
    if dns.endswith(".edu") or dns.endswith(".com") or dns.endswith(".org") or dns.endswith(".net") :
        dns = ".".join(pieces[-2:])
    else:
        dns = ".".join(pieces[-3:])
    dns = dnsmapping.get(dns,dns)
    return mpieces[0] + '@' + dns
def parsemaildate(md) :
    # See if we have dateutil
    try:
        pdate = parser.parse(tdate)
        test_at = pdate.isoformat()
        return test_at
    except:
        pass
    # Non-dateutil version - we try our best
    pieces = md.split()
    notz = " ".join(pieces[:4]).strip()
    # Try a bunch of format variations - strptime() is *lame*
    dnotz = None
    for form in [ '%d %b %Y %H:%M:%S', '%d %b %Y %H:%M:%S', 
        '%d %b %Y %H:%M', '%d %b %Y %H:%M', '%d %b %y %H:%M:%S', 
        '%d %b %y %H:%M:%S', '%d %b %y %H:%M', '%d %b %y %H:%M' ] :
        try:
            dnotz = datetime.strptime(notz, form)
            break
        except:
            continue
    if dnotz is None :
        return None
    iso = dnotz.isoformat()
    tz = "+0000"
    try:
        tz = pieces[4]
        ival = int(tz) # Only want numeric timezone values
        if tz == '-0000' : tz = '+0000'
        tzh = tz[:3]
        tzm = tz[3:]
        tz = tzh+":"+tzm
    except:
        pass
    return iso+tz
# Parse out the info...
def parseheader(hdr, allsenders=None):
    if hdr is None or len(hdr) < 1 : return None
    sender = None
    x = re.findall('\nFrom: .* <(\S+@\S+)>\n', hdr)
    if len(x) >= 1 :
        sender = x[0]
    else:
        x = re.findall('\nFrom: (\S+@\S+)\n', hdr)
        if len(x) >= 1 :
            sender = x[0]
    # normalize the domain name of Email addresses
    sender = fixsender(sender, allsenders)
    date = None
    y = re.findall('\nDate: .*, (.*)\n', hdr)
    sent_at = None
    if len(y) >= 1 :
        tdate = y[0]
        tdate = tdate[:26]
        try:
            sent_at = parsemaildate(tdate)
        except Exception, e:
            # print 'Date ignored ',tdate, e
            return None
    subject = None
    z = re.findall('\nSubject: (.*)\n', hdr)
    if len(z) >= 1 : subject = z[0].strip().lower()
    guid = None
    z = re.findall('\nMessage-ID: (.*)\n', hdr)
    if len(z) >= 1 : guid = z[0].strip().lower()
    if sender is None or sent_at is None or subject is None or guid is None :
        return None
    return (guid, sender, subject, sent_at)
conn = sqlite3.connect('index-demo.sqlite')
conn.text_factory = str
cur = conn.cursor()
cur.execute('''DROP TABLE IF EXISTS Messages ''')
cur.execute('''DROP TABLE IF EXISTS Senders ''')
cur.execute('''DROP TABLE IF EXISTS Subjects ''')
cur.execute('''DROP TABLE IF EXISTS Replies ''')
cur.execute('''CREATE TABLE IF NOT EXISTS Messages 
    (id INTEGER PRIMARY KEY, guid TEXT UNIQUE, sent_at INTEGER, 
     sender_id INTEGER, subject_id INTEGER, 
     headers BLOB, body BLOB)''')
cur.execute('''CREATE TABLE IF NOT EXISTS Senders 
    (id INTEGER PRIMARY KEY, sender TEXT UNIQUE)''')
cur.execute('''CREATE TABLE IF NOT EXISTS Subjects 
    (id INTEGER PRIMARY KEY, subject TEXT UNIQUE)''')
cur.execute('''CREATE TABLE IF NOT EXISTS Replies 
    (from_id INTEGER, to_id INTEGER)''')
conn_1 = sqlite3.connect('content-demo.sqlite')
conn_1.text_factory = str
cur_1 = conn_1.cursor()
cur_1.execute('''SELECT old,new FROM DNSMapping''')
for message_row in cur_1 :
    dnsmapping[message_row[0].strip().lower()] = message_row[1].strip().lower()
mapping = dict()
cur_1.execute('''SELECT old,new FROM Mapping''')
for message_row in cur_1 :
    old = fixsender(message_row[0])
    new = fixsender(message_row[1])
    mapping[old] = fixsender(new)
allsenders = list()
cur_1.execute('''SELECT email FROM Messages''')
for message_row in cur_1 :
    sender = fixsender(message_row[0])
    if sender is None : continue
    if 'gmane.org' in sender : continue
    if sender in allsenders: continue
    allsenders.append(sender)
print "Loaded allsenders",len(allsenders),"and mapping",len(mapping),"dns mapping",len(dnsmapping)
cur_1.execute('''SELECT headers, body, sent_at 
    FROM Messages ORDER BY sent_at''')
senders = dict()
subjects = dict()
guids = dict()
count = 0
for message_row in cur_1 :
    hdr = message_row[0]
    parsed = parseheader(hdr, allsenders)
    if parsed is None: continue
    (guid, sender, subject, sent_at) = parsed
    # Apply the sender mapping
    sender = mapping.get(sender,sender)
    count = count + 1
    if count % 250 == 1 : print count,sent_at, sender
    # print guid, sender, subject, sent_at
    if 'gmane.org' in sender:
        print "Error in sender ===", sender
    sender_id = senders.get(sender,None)
    subject_id = subjects.get(subject,None)
    guid_id = guids.get(guid,None)
    if sender_id is None : 
        cur.execute('INSERT OR IGNORE INTO Senders (sender) VALUES ( ? )', ( sender, ) )
        conn.commit()
        cur.execute('SELECT id FROM Senders WHERE sender=? LIMIT 1', ( sender, ))
        try:
            row = cur.fetchone()
            sender_id = row[0]
            senders[sender] = sender_id
        except:
            print 'Could not retrieve sender id',sender
            break
    if subject_id is None : 
        cur.execute('INSERT OR IGNORE INTO Subjects (subject) VALUES ( ? )', ( subject, ) )
        conn.commit()
        cur.execute('SELECT id FROM Subjects WHERE subject=? LIMIT 1', ( subject, ))
        try:
            row = cur.fetchone()
            subject_id = row[0]
            subjects[subject] = subject_id
        except:
            print 'Could not retrieve subject id',subject
            break
    # print sender_id, subject_id
    cur.execute('INSERT OR IGNORE INTO Messages (guid,sender_id,subject_id,sent_at,headers,body) VALUES ( ?,?,?,datetime(?),?,? )', 
            ( guid, sender_id, subject_id, sent_at, zlib.compress(message_row[0]), zlib.compress(message_row[1])) )
    conn.commit()
    cur.execute('SELECT id FROM Messages WHERE guid=? LIMIT 1', ( guid, ))
    try:
        row = cur.fetchone()
        message_id = row[0]
        guids[guid] = message_id
    except:
        print 'Could not retrieve guid id',guid
        break
cur.close()
cur_1.close()
print "\ngbasic.py"
# ************************************** gbasic.py *************************************
# ******************************** basic analysis step *********************************
import sqlite3
import time
import urllib
import zlib
howmany = 3
conn = sqlite3.connect('index-demo.sqlite')
conn.text_factory = str
cur = conn.cursor()
cur.execute('SELECT id, sender FROM Senders')
senders = dict()
for message_row in cur :
    senders[message_row[0]] = message_row[1]
cur.execute('SELECT id, subject FROM Subjects')
subjects = dict()
for message_row in cur :
    subjects[message_row[0]] = message_row[1]
cur.execute('SELECT id, guid,sender_id,subject_id,sent_at FROM Messages')
messages = dict()
for message_row in cur :
    messages[message_row[0]] = (message_row[1],message_row[2],message_row[3],message_row[4])
print "Loaded messages=",len(messages),"subjects=",len(subjects),"senders=",len(senders)
sendcounts = dict()
sendorgs = dict()
for (message_id, message) in messages.items():
    sender = message[1]
    sendcounts[sender] = sendcounts.get(sender,0) + 1
    pieces = senders[sender].split("@")
    if len(pieces) != 2 : continue
    dns = pieces[1]
    sendorgs[dns] = sendorgs.get(dns,0) + 1
print ''
print 'Top',howmany,'Email list participants'
x = sorted(sendcounts, key=sendcounts.get, reverse=True)
for k in x[:howmany]:
    print senders[k], sendcounts[k]
    if sendcounts[k] < 10 : break
print ''
print 'Top',howmany,'Email list organizations'
x = sorted(sendorgs, key=sendorgs.get, reverse=True)
for k in x[:howmany]:
    print k, sendorgs[k]
    if sendorgs[k] < 10 : break
print "\ngword.py"
# ************************************** gword.py **************************************
# ******************************** word visualization **********************************
import sqlite3
import time
import urllib
import zlib
import string
conn = sqlite3.connect('index-demo.sqlite')
conn.text_factory = str
cur = conn.cursor()
cur.execute('SELECT id, subject FROM Subjects')
subjects = dict()
for message_row in cur :
    subjects[message_row[0]] = message_row[1]
cur.execute('SELECT subject_id FROM Messages')
counts = dict()
for message_row in cur :
    text = subjects[message_row[0]]
    text = text.translate(None, string.punctuation)
    text = text.translate(None, '1234567890')
    text = text.strip()
    text = text.lower()
    words = text.split()
    for word in words:
        if len(word) < 4 : continue
        counts[word] = counts.get(word,0) + 1
x = sorted(counts, key=counts.get, reverse=True)
highest = None
lowest = None
for k in x[:100]:
    if highest is None or highest < counts[k] :
        highest = counts[k]
    if lowest is None or lowest > counts[k] :
        lowest = counts[k]
print 'Range of counts:',highest,lowest
bigsize = 80
smallsize = 20
fhand = open('gword-demo.js','w')
fhand.write("gword = [")
first = True
for k in x[:100]:
    if not first : fhand.write( ",\n")
    first = False
    size = counts[k]
    size = (size - lowest) / float(highest - lowest)
    size = int((size * bigsize) + smallsize)
    fhand.write("{text: '"+k+"', size: "+str(size)+"}")
fhand.write( "\n];\n")
print "Output written to gword-demo.js"
print "\ngline.py"
# ************************************** gline.py **************************************
# ******************************** line visualization **********************************
import sqlite3
import time
import urllib
import zlib
conn = sqlite3.connect('index-demo.sqlite')
conn.text_factory = str
cur = conn.cursor()
cur.execute('SELECT id, sender FROM Senders')
senders = dict()
for message_row in cur :
    senders[message_row[0]] = message_row[1]
cur.execute('SELECT id, guid,sender_id,subject_id,sent_at FROM Messages')
messages = dict()
for message_row in cur :
    messages[message_row[0]] = (message_row[1],message_row[2],message_row[3],message_row[4])
print "Loaded messages=",len(messages),"senders=",len(senders)
sendorgs = dict()
for (message_id, message) in messages.items():
    sender = message[1]
    pieces = senders[sender].split("@")
    if len(pieces) != 2 : continue
    dns = pieces[1]
    sendorgs[dns] = sendorgs.get(dns,0) + 1
orgs = sorted(sendorgs, key=sendorgs.get, reverse=True)
orgs = orgs[:10]
print "Top 10 Oranizations"
print orgs
counts = dict()
months = list()
for (message_id, message) in messages.items():
    sender = message[1]
    pieces = senders[sender].split("@")
    if len(pieces) != 2 : continue
    dns = pieces[1]
    if dns not in orgs : continue
    month = message[3][:7]
    if month not in months : months.append(month)
    key = (month, dns)
    counts[key] = counts.get(key,0) + 1
months.sort()
fhand = open('gline-demo.js','w')
fhand.write("gline = [ ['Year'")
for org in orgs:
    fhand.write(",'"+org+"'")
fhand.write("]")

for month in months:
    fhand.write(",\n['"+month+"'")
    for org in orgs:
        key = (month, org)
        val = counts.get(key,0)
        fhand.write(","+str(val))
    fhand.write("]");
fhand.write("\n];\n")
print "Output written to gline-demo.js"
```

###18) gmane mailing lists demo2
```{r echo=FALSE}
print "visualizing gword-demo.js & gline-demo.js"
# ************************** gword-demo.js & gline-demo.js *****************************
# ****************************** word visualization step *******************************
```
<html><head>
<meta charset="utf-8">
<script src="d3.v2.js"></script>
<script src="d3.layout.cloud.js"></script>
<script src="gword-demo.js"></script>
</head>
<body>
<script>
  var fill = d3.scale.category20();
  d3.layout.cloud().size([400, 400])
      .words(gword)
      .rotate(function() { return ~~(Math.random() * 2) * 90; })
      .font("Impact")
      .fontSize(function(d) { return d.size; })
      .on("end", draw)
      .start();
  function draw(words) {
    d3.select("body").append("svg")
        .attr("width", 700)
        .attr("height", 700)
      .append("g")
        .attr("transform", "translate(350,350)")
      .selectAll("text")
        .data(words)
      .enter().append("text")
        .style("font-size", function(d) { return d.size + "px"; })
        .style("font-family", "Impact")
        .style("fill", function(d, i) { return fill(i); })
        .attr("text-anchor", "middle")
        .attr("transform", function(d) {
          return "translate(" + [d.x, d.y] + ")rotate(" + d.rotate + ")";
        })
        .text(function(d) { return d.text; });}
</script>
</body>
</html>
<br><br>
<html><head>
<script type="text/javascript" src="gline-demo.js"></script>
<script type="text/javascript" src="https://www.google.com/jsapi"></script>
<script type="text/javascript">
      google.load("visualization", "1", {packages:["corechart"]});
      google.setOnLoadCallback(drawChart);
      function drawChart() {
        var data = google.visualization.arrayToDataTable( gline );
        var options = {
          title: 'Sakai Developer Email Participation by Organization'
        };
        var chart = new google.visualization.LineChart(document.getElementById('chart_div'));
        chart.draw(data, options);}
</script>
</head>
<body><div id="chart_div" style="width: 400px; height: 120px;"></div></body>
</html>
